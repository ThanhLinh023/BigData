{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/15 14:24:27 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"SparkMLLib_NaiveBayes\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/15 14:24:29 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load training data\n",
    "data = spark.read.format(\"libsvm\").load(\"./sample_libsvm_data.txt\")\n",
    "\n",
    "data.show()\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test\n",
    "splits = data.randomSplit([0.6, 0.4], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "\n",
    "# train the model\n",
    "model = nb.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dau tien chia bo du lieu thanh train test voi ti le 60:40. Sau do khoi tao mo hinh NaiveBayes voi tham so smoothing de lam tron Laplace va tham so modelType la \"multinomial\" de thich hop voi du lieu dau vao co dac trung roi rac. Sau do phuong thuc fit() de thuc hien train model tren train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/15 14:24:54 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+-----------+----------+\n",
      "|label|            features|       rawPrediction|probability|prediction|\n",
      "+-----+--------------------+--------------------+-----------+----------+\n",
      "|  0.0|(692,[95,96,97,12...|[-172664.79564650...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[98,99,100,1...|[-176279.15054306...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[122,123,124...|[-189600.55409526...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[-274673.88337431...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[-183393.03869049...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[125,126,127...|[-256992.48807619...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[-210411.53649773...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[-170627.63616681...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[-212157.96750469...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[-183253.80108550...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[128,129,130...|[-246528.93739632...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[150,151,152...|[-158348.34683571...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[-210229.50765957...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[-242985.16248889...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[-94622.933454005...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[153,154,155...|[-266465.39689814...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[153,154,155...|[-144989.71469229...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[154,155,156...|[-283834.57437738...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[181,182,183...|[-155256.59399829...|  [1.0,0.0]|       0.0|\n",
      "|  1.0|(692,[100,101,102...|[-147726.11958982...|  [0.0,1.0]|       1.0|\n",
      "+-----+--------------------+--------------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# select example rows to display.\n",
    "predictions = model.transform(test)\n",
    "predictions.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions de dua ra du doan cua mo hinh NaiveBayes dua tren test data. MulticlassClassificationEvaluator la cong cu dung de danh gia mo hinh phan loai da lop trong Spark. Phuong thuc evaluate() tinh toan chi so duoc chi dinh - o day la accuracy la do chinh xac. Va o duoi la do chinh xac cua du lieu test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
